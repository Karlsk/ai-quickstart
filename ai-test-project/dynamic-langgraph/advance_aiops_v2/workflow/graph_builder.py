"""
åŠ¨æ€å›¾æ„å»ºå™¨
æ ¹æ®å·¥ä½œæµå®šä¹‰åŠ¨æ€æ„å»º LangGraph çŠ¶æ€å›¾
æ”¯æŒæ™®é€šè¾¹å’Œæ¡ä»¶è¾¹çš„è‡ªåŠ¨å¤„ç†
"""

from typing import Dict, Any, Callable, Optional, Type
from pydantic import create_model, BaseModel, Field
from langgraph.graph import StateGraph, END
import logging

from .models import (
    WorkflowDefinition, NodeDefinition, EdgeDefinition, StateFieldSchema,
    OperatorLog, NodeType, ExecutionLog
)
from .base_node import BaseNode, create_node

logger = logging.getLogger(__name__)


def auto_generate_operator_logs(definition: WorkflowDefinition) -> None:
    """
    è‡ªåŠ¨ä¸ºå·¥ä½œæµçš„èŠ‚ç‚¹ç”Ÿæˆ operator_logs
    å¦‚æœèŠ‚ç‚¹å·²æœ‰ operator_logï¼Œåˆ™ä¿æŒä¸å˜
    
    Args:
        definition: å·¥ä½œæµå®šä¹‰ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
    """
    if not definition.operator_logs:
        definition.operator_logs = {}
    
    # ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆ operator_logï¼ˆå¦‚æœè¿˜æ²¡æœ‰çš„è¯ï¼‰
    for node_def in definition.nodes:
        if node_def.name not in definition.operator_logs:
            # æ ¹æ®èŠ‚ç‚¹ç±»å‹ç”Ÿæˆåˆç†çš„ schema
            if node_def.type == NodeType.Planner:
                # Planner èŠ‚ç‚¹ï¼šæ¥æ”¶ inputï¼Œè¾“å‡º plan
                op_log = OperatorLog(
                    node_name=node_def.name,
                    input_schema={
                        "input": StateFieldSchema(type="str", description="è¾“å…¥æŸ¥è¯¢")
                    },
                    output_schema={
                        "plan": StateFieldSchema(type="str", description="è§„åˆ’ç»“æœ"),
                        "status": StateFieldSchema(type="str", description="çŠ¶æ€")
                    }
                )
            elif node_def.type == NodeType.Worker:
                # Worker èŠ‚ç‚¹ï¼šæ¥æ”¶å‰é¢èŠ‚ç‚¹çš„ç»“æœï¼Œè¾“å‡ºæ‰§è¡Œç»“æœ
                op_log = OperatorLog(
                    node_name=node_def.name,
                    input_schema={
                        "plan": StateFieldSchema(type="str", description="è¾“å…¥è®¡åˆ’")
                    },
                    output_schema={
                        "result": StateFieldSchema(type="str", description="æ‰§è¡Œç»“æœ")
                    }
                )
            elif node_def.type == NodeType.Reflection:
                # Reflection èŠ‚ç‚¹ï¼šæ¥æ”¶ resultï¼Œè¾“å‡º reflection
                op_log = OperatorLog(
                    node_name=node_def.name,
                    input_schema={
                        "result": StateFieldSchema(type="str", description="è¾“å…¥ç»“æœ")
                    },
                    output_schema={
                        "reflection": StateFieldSchema(type="str", description="åæ€ç»“æœ"),
                        "status": StateFieldSchema(type="str", description="çŠ¶æ€")
                    }
                )
            elif node_def.type == NodeType.Agent:
                # Agent èŠ‚ç‚¹ï¼šåŠ¨æ€å·¥ä½œæµ
                op_log = OperatorLog(
                    node_name=node_def.name,
                    input_schema={
                        "input": StateFieldSchema(type="str", description="è¾“å…¥")
                    },
                    output_schema={
                        "output": StateFieldSchema(type="str", description="è¾“å‡º")
                    }
                )
            else:
                # å…¶ä»–ç±»å‹ï¼šåˆ›å»ºç©ºçš„ operator_log
                op_log = OperatorLog(
                    node_name=node_def.name,
                    input_schema={},
                    output_schema={}
                )
            
            definition.operator_logs[node_def.name] = op_log


class GraphBuilder:
    """
    å·¥ä¸šçº§çš„åŠ¨æ€å›¾æ„å»ºå™¨
    è´Ÿè´£æ ¹æ®å·¥ä½œæµå®šä¹‰æ„å»ºç¼–è¯‘åçš„ LangGraph
    """
    
    def __init__(self, workflow_registry: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–å›¾æ„å»ºå™¨
        
        Args:
            workflow_registry: å·¥ä½œæµæ³¨å†Œè¡¨ï¼Œç”¨äº Agent èŠ‚ç‚¹å¼•ç”¨
        """
        self.workflow_registry = workflow_registry or {}
        self._parent_registry = None
    
    def set_parent_registry(self, parent_registry: 'WorkflowRegistry') -> None:
        """è®¾ç½®çˆ¶çº§WorkflowRegistryï¼Œç”¨äºAgentèŠ‚ç‚¹æŸ¥è¯¢å·²æ³¨å†Œçš„å·¥ä½œæµ"""
        self._parent_registry = parent_registry
    
    def build_graph(self, definition: WorkflowDefinition) -> Any:
        """
        æ ¹æ®å·¥ä½œæµå®šä¹‰æ„å»º LangGraph
        
        Args:
            definition: å·¥ä½œæµå®šä¹‰
            
        Returns:
            ç¼–è¯‘åçš„ LangGraph
            
        Raises:
            ValueError: å·¥ä½œæµå®šä¹‰ä¸åˆæ³•
        """
        logger.info(f"Building workflow: {definition.workflow_id}")
        
        # 1. éªŒè¯å·¥ä½œæµå®šä¹‰
        self._validate_definition(definition)
        
        # 2. åˆ›å»ºåŠ¨æ€çŠ¶æ€æ¨¡å‹
        state_model = self._create_state_model(definition.state_schema)
        
        # 3. åˆ›å»ºçŠ¶æ€å›¾
        graph = StateGraph(state_model)
        
        # 4. åˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹å¹¶æ·»åŠ åˆ°å›¾ä¸­
        nodes_map = self._add_nodes_to_graph(graph, definition)
        
        # ä¿å­˜èŠ‚ç‚¹å¼•ç”¨åˆ°æ³¨å†Œè¡¨ï¼ˆä¾¿äºåç»­æŸ¥è¯¢æ‰§è¡Œæ—¥å¿—ï¼‰
        if self._parent_registry:
            self._parent_registry._nodes_map[definition.workflow_id] = nodes_map
        
        # 5. æ·»åŠ è¾¹
        self._add_edges_to_graph(graph, definition, nodes_map)
        
        # 6. è®¾ç½®å…¥å£ç‚¹
        graph.set_entry_point(definition.entry_point)
        
        # 7. ç¼–è¯‘å›¾
        compiled_graph = graph.compile()
        
        logger.info(f"Workflow '{definition.workflow_id}' built successfully")
        
        return compiled_graph
    
    def _validate_definition(self, definition: WorkflowDefinition) -> None:
        """éªŒè¯å·¥ä½œæµå®šä¹‰çš„åˆæ³•æ€§"""
        if not definition.workflow_id:
            raise ValueError("workflow_id is required")
        
        if not definition.nodes:
            raise ValueError(f"Workflow '{definition.workflow_id}': nodes list is empty")
        
        if not definition.entry_point:
            raise ValueError(f"Workflow '{definition.workflow_id}': entry_point is required")
        
        # éªŒè¯å…¥å£ç‚¹å­˜åœ¨
        node_names = {node.name for node in definition.nodes}
        if definition.entry_point not in node_names:
            raise ValueError(
                f"Workflow '{definition.workflow_id}': entry_point '{definition.entry_point}' not found in nodes"
            )
        
        # éªŒè¯æ‰€æœ‰è¾¹çš„æºå’Œç›®æ ‡å­˜åœ¨
        for edge in definition.edges:
            if edge.source not in node_names and edge.source != "END":
                raise ValueError(
                    f"Workflow '{definition.workflow_id}': edge source '{edge.source}' not found in nodes"
                )
            if edge.target not in node_names and edge.target != "END":
                raise ValueError(
                    f"Workflow '{definition.workflow_id}': edge target '{edge.target}' not found in nodes"
                )
    
    def _create_state_model(self, state_schema: Dict[str, StateFieldSchema]) -> Type[BaseModel]:
        """
        åŠ¨æ€åˆ›å»ºçŠ¶æ€æ¨¡å‹
        
        Args:
            state_schema: çŠ¶æ€å­—æ®µå®šä¹‰
            
        Returns:
            åŠ¨æ€åˆ›å»ºçš„ Pydantic BaseModel ç±»
        """
        field_definitions = {}
        
        # ç±»å‹æ˜ å°„
        TYPE_MAP = {
            "str": str,
            "int": int,
            "float": float,
            "bool": bool,
            "list": list,
            "dict": Any,  # dict ç±»å‹ç”¨ Any æ¥æ”¶ä»»æ„æ•°æ®
            "List[str]": list,
            "Dict[str, Any]": Any,
        }
        
        for field_name, field_schema in state_schema.items():
            py_type = TYPE_MAP.get(field_schema.type, str)
            default_val = field_schema.default
            
            field_definitions[field_name] = (
                py_type,
                Field(default=default_val, description=field_schema.description)
            )
        
        # è‡ªåŠ¨æ·»åŠ  history å­—æ®µç”¨äºè¿½è¸ªæ‰§è¡Œå†å²
        if "history" not in field_definitions:
            field_definitions["history"] = (
                list,
                Field(default_factory=list, description="Execution history tracking")
            )
        
        # å…³é”®ï¼šä½¿ç”¨ ConfigDict å…è®¸ä»»æ„å­—æ®µæ·»åŠ ï¼ˆDify é£æ ¼ï¼‰
        from pydantic import ConfigDict
        
        # åˆ›å»ºæœ‰ ConfigDict çš„åŸºç±»
        class DynamicStateBase(BaseModel):
            model_config = ConfigDict(extra='allow')
        
        # åŠ¨æ€åˆ›å»ºæ¨¡å‹ï¼Œç»§æ‰¿è‡ªå®šä¹‰åŸºç±»
        DynamicState = create_model(
            'DynamicWorkflowState',
            **field_definitions,
            __base__=DynamicStateBase
        )
        
        return DynamicState
    
    def _add_nodes_to_graph(
        self,
        graph: StateGraph,
        definition: WorkflowDefinition
    ) -> Dict[str, BaseNode]:
        """
        åˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹å¹¶æ·»åŠ åˆ°å›¾ä¸­
        
        Args:
            graph: StateGraph å®ä¾‹
            definition: å·¥ä½œæµå®šä¹‰
            
        Returns:
            èŠ‚ç‚¹åç§°åˆ°èŠ‚ç‚¹å®ä¾‹çš„æ˜ å°„
        """
        # æ„å»ºå¯ç”¨çš„å·¥ä½œæµæ³¨å†Œè¡¨ï¼ˆåŒ…æ‹¬å·²æ³¨å†Œçš„å’Œå½“å‰æ³¨å†Œä¸­çš„ï¼‰
        available_workflows = {}
        if self._parent_registry:
            available_workflows.update(self._parent_registry._registry)
        available_workflows.update(self.workflow_registry)
        
        nodes_map = {}
        
        for node_def in definition.nodes:
            try:
                # è·å–æ“ä½œç¬¦æ—¥å¿—
                operator_log = definition.operator_logs.get(node_def.name)
                
                # åˆ›å»ºèŠ‚ç‚¹
                node = create_node(
                    node_def,
                    operator_log=operator_log,
                    workflow_registry=available_workflows
                )
                
                # æ„å»ºèŠ‚ç‚¹çš„ Runnable
                runnable = node.build_runnable()
                
                # å¦‚æœèŠ‚ç‚¹æ²¡æœ‰ operator_logï¼Œä¸ºå…¶æ·»åŠ ä¸€ä¸ªç©ºçš„ï¼ˆæˆ–ä»èŠ‚ç‚¹æå–ï¼‰
                if not operator_log and hasattr(node, 'operator_log'):
                    definition.operator_logs[node_def.name] = node.operator_log
                
                # æ·»åŠ åˆ°å›¾ä¸­
                graph.add_node(node_def.name, runnable)
                
                nodes_map[node_def.name] = node
                
                logger.debug(f"Added node: {node_def.name} (type: {node_def.type})")
                
            except Exception as e:
                logger.error(f"Failed to create node '{node_def.name}': {e}")
                raise
        
        return nodes_map
    
    def _add_edges_to_graph(
        self,
        graph: StateGraph,
        definition: WorkflowDefinition,
        nodes_map: Dict[str, BaseNode]
    ) -> None:
        """
        æ·»åŠ è¾¹åˆ°å›¾ä¸­
        æ”¯æŒæ™®é€šè¾¹å’Œæ¡ä»¶è¾¹
        
        Args:
            graph: StateGraph å®ä¾‹
            definition: å·¥ä½œæµå®šä¹‰
            nodes_map: èŠ‚ç‚¹æ˜ å°„
        """
        for edge_def in definition.edges:
            source = edge_def.source
            target = edge_def.target
            condition = edge_def.condition
            
            try:
                # å¤„ç†ç›®æ ‡èŠ‚ç‚¹
                if target == "END":
                    target_obj = END
                else:
                    target_obj = target
                
                # æ ¹æ®æ˜¯å¦æœ‰æ¡ä»¶æ¥å¤„ç†
                if condition:
                    # æ·»åŠ æ¡ä»¶è¾¹
                    self._add_conditional_edge(graph, source, target_obj, condition)
                else:
                    # æ·»åŠ æ™®é€šè¾¹
                    self._add_normal_edge(graph, source, target_obj)
                
                logger.debug(f"Added edge: {source} -> {target}" + 
                           (f" (condition: {condition})" if condition else ""))
                
            except Exception as e:
                logger.error(f"Failed to add edge {source} -> {target}: {e}")
                raise
    
    def _add_normal_edge(self, graph: StateGraph, source: str, target: Any) -> None:
        """æ·»åŠ æ™®é€šè¾¹"""
        graph.add_edge(source, target)
    
    def _add_conditional_edge(
        self,
        graph: StateGraph,
        source: str,
        target: Any,
        condition_key: str
    ) -> None:
        """
        æ·»åŠ æ¡ä»¶è¾¹
        
        Args:
            graph: StateGraph å®ä¾‹
            source: æºèŠ‚ç‚¹åç§°
            target: ç›®æ ‡èŠ‚ç‚¹ï¼ˆå¯ä»¥æ˜¯èŠ‚ç‚¹åç§°æˆ– ENDï¼‰
            condition_key: æ¡ä»¶è·¯ç”±é”®å
        """
        def router_func(state: Any) -> str:
            """
            è·¯ç”±å‡½æ•°ï¼šæ ¹æ®çŠ¶æ€ä¸­çš„æ¡ä»¶é”®ç¡®å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
            """
            # å°† Pydantic æ¨¡å‹è½¬æ¢ä¸ºå­—å…¸
            if hasattr(state, 'model_dump'):
                state_dict = state.model_dump()
            else:
                state_dict = state
            
            # è·å–æ¡ä»¶å€¼
            condition_value = state_dict.get(condition_key)
            
            # å¦‚æœæ¡ä»¶å€¼ä¸º None æˆ–ç©ºï¼Œè¿”å›åŸå§‹ç›®æ ‡
            if condition_value is None:
                return target if isinstance(target, str) else "END"
            
            # å¦‚æœæ¡ä»¶å€¼åŒ¹é…ç›®æ ‡èŠ‚ç‚¹åç§°æˆ–æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„è·¯ç”±å€¼
            # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´å¤æ‚çš„è·¯ç”±é€»è¾‘
            return condition_value if isinstance(condition_value, str) else str(condition_value)
        
        # æ·»åŠ æ¡ä»¶è¾¹
        # path_map éœ€è¦åŒ…å«æ‰€æœ‰å¯èƒ½çš„è·¯ç”±å€¼åˆ°ç›®æ ‡èŠ‚ç‚¹çš„æ˜ å°„
        path_map = {}
        if isinstance(target, str):
            path_map[target] = target
            path_map[condition_key] = target
        
        graph.add_conditional_edges(source, router_func, path_map)


class WorkflowRegistry:
    """
    å·¥ä½œæµæ³¨å†Œè¡¨
    ç®¡ç†å·²ç¼–è¯‘çš„å·¥ä½œæµï¼Œæ”¯æŒå­˜å‚¨ã€åŠ è½½å’Œæ‰§è¡Œ
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ³¨å†Œè¡¨"""
        self._registry: Dict[str, Any] = {}
        self._definitions: Dict[str, WorkflowDefinition] = {}  # å­˜å‚¨å·¥ä½œæµå®šä¹‰
        self._nodes_map: Dict[str, Dict[str, BaseNode]] = {}  # å­˜å‚¨æ¯ä¸ªå·¥ä½œæµçš„èŠ‚ç‚¹
        self._graph_builder = GraphBuilder(self._registry)
        self._graph_builder.set_parent_registry(self)
    
    def register_workflow(self, definition: WorkflowDefinition) -> str:
        """
        æ³¨å†Œï¼ˆç¼–è¯‘ï¼‰ä¸€ä¸ªå·¥ä½œæµ
        
        Args:
            definition: å·¥ä½œæµå®šä¹‰
            
        Returns:
            å·¥ä½œæµ ID
        """
        try:
            # è‡ªåŠ¨ä¸ºæ²¡æœ‰ operator_logs çš„èŠ‚ç‚¹ç”Ÿæˆé»˜è®¤å€¼
            auto_generate_operator_logs(definition)
            
            # ä¿å­˜å·¥ä½œæµå®šä¹‰
            self._definitions[definition.workflow_id] = definition
            
            compiled_graph = self._graph_builder.build_graph(definition)
            self._registry[definition.workflow_id] = compiled_graph
            logger.info(f"Workflow '{definition.workflow_id}' registered successfully")
            return definition.workflow_id
        except Exception as e:
            logger.error(f"Failed to register workflow '{definition.workflow_id}': {e}")
            raise
    
    def get_workflow(self, workflow_id: str) -> Any:
        """
        è·å–å·²æ³¨å†Œçš„å·¥ä½œæµ
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            
        Returns:
            ç¼–è¯‘åçš„å·¥ä½œæµ
            
        Raises:
            ValueError: å·¥ä½œæµä¸å­˜åœ¨
        """
        if workflow_id not in self._registry:
            raise ValueError(f"Workflow '{workflow_id}' not found in registry")
        return self._registry[workflow_id]
    
    def has_workflow(self, workflow_id: str) -> bool:
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å­˜åœ¨"""
        return workflow_id in self._registry
    
    def list_workflows(self) -> list[str]:
        """åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„å·¥ä½œæµ ID"""
        return list(self._registry.keys())
    
    def unregister_workflow(self, workflow_id: str) -> bool:
        """
        ç§»é™¤ä¸€ä¸ªå·¥ä½œæµ
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            
        Returns:
            æ˜¯å¦æˆåŠŸç§»é™¤
        """
        if workflow_id in self._registry:
            del self._registry[workflow_id]
            logger.info(f"Workflow '{workflow_id}' unregistered")
            return True
        return False
    
    def execute_workflow(self, workflow_id: str, input_data: Dict[str, Any]) -> Any:
        """
        æ‰§è¡Œä¸€ä¸ªå·¥ä½œæµ
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            input_data: è¾“å…¥æ•°æ®
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        workflow = self.get_workflow(workflow_id)
        logger.info(f"Executing workflow '{workflow_id}'")
        
        try:
            result = workflow.invoke(input_data)
            logger.info(f"Workflow '{workflow_id}' executed successfully")
            
            # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„æ‰§è¡Œæ—¥å¿—å›å·¥ä½œæµå®šä¹‰
            self._collect_execution_logs(workflow_id)
            
            return result
        except Exception as e:
            logger.error(f"Workflow '{workflow_id}' execution failed: {e}")
            raise
    
    def get_registry_stats(self) -> Dict[str, Any]:
        """è·å–æ³¨å†Œè¡¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_workflows": len(self._registry),
            "workflow_ids": self.list_workflows()
        }
    
    def _collect_execution_logs(self, workflow_id: str) -> None:
        """
        æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„æ‰§è¡Œæ—¥å¿—ä¸¦å¤‰æ–°åˆ°å·¥ä½œæµå®šä¹‰
        
        Args:
            workflow_id: å·¥ä½œæµ ID
        """
        definition = self.get_workflow_definition(workflow_id)
        if not definition:
            return
        
        nodes_map = self._nodes_map.get(workflow_id, {})
        execution_history = []
        
        # æ”¶é›†æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæ—¥å¿—
        for node_name, node in nodes_map.items():
            node_logs = node.get_execution_history()
            execution_history.extend(node_logs)
        
        # æŒ‰æ—¶é—´æ’åºæ‰§è¡Œæ—¥å¿—
        execution_history.sort(key=lambda log: log.timestamp)
        
        # æ›´æ–°å·¥ä½œæµå®šä¹‰ä¸­çš„æ‰§è¡Œå†å²
        definition.execution_history = execution_history
    
    # --- æŸ¥è¯¢æ¥å£ ---
    
    def get_workflow_definition(self, workflow_id: str) -> Optional[WorkflowDefinition]:
        """
        è·å–å·¥ä½œæµçš„å®šä¹‰
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            
        Returns:
            å·¥ä½œæµå®šä¹‰ï¼Œä¸å­˜åœ¨æ™‚è¿”å› None
        """
        return self._definitions.get(workflow_id)
    
    def get_operator_logs(self, workflow_id: str) -> Dict[str, OperatorLog]:
        """
        è·å–å·¥ä½œæµçš„æ“ä½œç¬¦æ—¥å¿—
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            
        Returns:
            æ“ä½œç¬¦æ—¥å¿—å­—å…¸ {node_name: OperatorLog}
        """
        definition = self.get_workflow_definition(workflow_id)
        if not definition:
            logger.warning(f"Workflow '{workflow_id}' not found")
            return {}
        return definition.operator_logs
    
    def get_operator_log_by_node(self, workflow_id: str, node_name: str) -> Optional[OperatorLog]:
        """
        è·å–ç‰¹å®šèŠ‚ç‚¹çš„æ“ä½œç¬¦æ—¥å¿—
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            node_name: èŠ‚ç‚¹åç§°
            
        Returns:
            æ“ä½œç¬¦æ—¥å¿—ï¼Œä¸å­˜åœ¨æ™‚è¿”å› None
        """
        logs = self.get_operator_logs(workflow_id)
        return logs.get(node_name)
    
    def get_execution_history(self, workflow_id: str) -> list[ExecutionLog]:
        """
        è·å–å·¥ä½œæµçš„æ‰§è¡Œå†å²
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            
        Returns:
            æ‰§è¡Œæ—¥å¿—åˆ—è¡¨ [ExecutionLog]
        """
        definition = self.get_workflow_definition(workflow_id)
        if not definition:
            logger.warning(f"Workflow '{workflow_id}' not found")
            return []
        return definition.execution_history
    
    def get_node_execution_history(self, workflow_id: str, node_name: str) -> list[ExecutionLog]:
        """
        è·å–ç‰¹å®šèŠ‚ç‚¹çš„æ‰§è¡Œå†å²
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            node_name: èŠ‚ç‚¹åç§°
            
        Returns:
            ç‰¹å®šèŠ‚ç‚¹çš„æ‰§è¡Œæ—¥å¿—åˆ—è¡¨
        """
        history = self.get_execution_history(workflow_id)
        return [log for log in history if log.node_name == node_name]
    
    def get_node_by_name(self, workflow_id: str, node_name: str) -> Optional[BaseNode]:
        """
        è·å–ç‰¹å®šèŠ‚ç‚¹çš„å¯¹è±¡ï¼ˆä¾¿äºç›´æ¥è°ƒç”¨å…¶æ–¹æ³•ï¼‰
        
        Args:
            workflow_id: å·¥ä½œæµ ID
            node_name: èŠ‚ç‚¹åç§°
            
        Returns:
            èŠ‚ç‚¹å¯¹è±¡ï¼Œä¸å­˜åœ¨æ™‚è¿”å› None
        """
        nodes_map = self._nodes_map.get(workflow_id, {})
        return nodes_map.get(node_name)
    
    def print_workflow_logs(self, workflow_id: str) -> None:
        """
        æ‰“å°å·¥ä½œæµçš„å…¨éƒ¨æ—¥å¿—ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
        
        Args:
            workflow_id: å·¥ä½œæµ ID
        """
        definition = self.get_workflow_definition(workflow_id)
        if not definition:
            print(f"\u26a0ï¸  å·¥ä½œæµ '{workflow_id}' ä¸å­˜åœ¨")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“„ å·¥ä½œæµæ—¥å¿—: {workflow_id}")
        print(f"{'='*80}")
        
        # æ‰“å°æ“ä½œç¬¦æ—¥å¿—
        if definition.operator_logs:
            print(f"\nğŸ’¼ æ“ä½œç¬¦æ—¥å¿— (OperatorLog):")
            print("-" * 80)
            for node_name, op_log in definition.operator_logs.items():
                print(f"  èŠ‚ç‚¹: {node_name}")
                print(f"    è¾“å…¥ Schema:")
                for field_name, field_schema in op_log.input_schema.items():
                    print(f"      - {field_name}: {field_schema.type} ({field_schema.description})")
                print(f"    è¾“å‡º Schema:")
                for field_name, field_schema in op_log.output_schema.items():
                    print(f"      - {field_name}: {field_schema.type} ({field_schema.description})")
        
        # æ‰“å°æ‰§è¡Œå†å²
        if definition.execution_history:
            print(f"\nâ±ï¸  æ‰§è¡Œå†å² (ExecutionLog):")
            print("-" * 80)
            for idx, exec_log in enumerate(definition.execution_history, 1):
                print(f"  [{idx}] {exec_log.node_name} ({exec_log.node_type.value})")
                print(f"      æ‰§è¡Œæ—¶é—´: {exec_log.timestamp}")
                print(f"      è€—æ—¶: {exec_log.execution_time_ms:.2f}ms")
                if exec_log.error:
                    print(f"      é”™è¯¯: {exec_log.error}")
                else:
                    print(f"      è¾“å…¥: {exec_log.input_data}")
                    print(f"      è¾“å‡º: {exec_log.output_data}")
        else:
            print("\n  æš‚æ— æ‰§è¡Œæ—¥å¿—")
        
        print(f"{'='*80}\n")
