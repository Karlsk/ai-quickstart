{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4601721",
   "metadata": {},
   "source": [
    "## 1. 管理工具安装\n",
    "### 1.1 langchain 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd141dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "\n",
    "# conda \n",
    "# conda install -c conda-forge langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3439ca0",
   "metadata": {},
   "source": [
    "### 1.2 其他库安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502417b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接转换为 REST API\n",
    "!pip install \"langserve[all]\"\n",
    "\n",
    "# 观测平台\n",
    "!pip install -U langsmith\n",
    "\n",
    "# LangGraph\n",
    "!pip install -U langgraph\n",
    "\n",
    "# DeepSeek\n",
    "!pip install langchain-deepseek\n",
    "\n",
    "# 外部资源集成\n",
    "!pip install langchain_community\n",
    "\n",
    "# dotenv管理密钥，加载环境变量等\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f13df0",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 常见的处理链包含三个要素\n",
    "\n",
    "1. 语言模型：核心推理引擎\n",
    "2. 提示词模板：提供指令\n",
    "3. 输出解释器：转换为易于使用的格式，便于下游处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f39bad",
   "metadata": {},
   "source": [
    "#### 1.3.1 语言模型\n",
    "\n",
    "langchain语言模型主要分为两种：\n",
    "\n",
    "1. LLM 通用模型：接收字符串作为输入，输出字符串作为输出。\n",
    "2. ChatModel 对话模型：接收消息列表，输出“消息”，用于一问一答。\n",
    "\n",
    "消息：由 BaseMessage 类定义，包含文本、时间戳、用户标识符等属性。主要的有\n",
    "\n",
    "1. 消息的内容：文本，通常是字符串\n",
    "2. 角色：消息的发送方\n",
    "\n",
    "角色： LangChain 用于区分不同角色的对象\n",
    "\n",
    "1. HumanMessage：人类（用户）输入的BaseMessage。\n",
    "2. AIMessage：AI助手（大模型）输出的BaseMessage。\n",
    "3. SystemMessage：系统预设的BaseMessage。\n",
    "4. FunctionMessage：自定义函数输出的BaseMessage。\n",
    "5. ToolMessage：调用第三方工具输出的BaseMessage。\n",
    "6. ChatMessage：自定义角色。\n",
    "\n",
    "方法： LCEL 默认实现同步调用方法，最常见的是 invoke 方法，接受一个 BaseMessage 对象作为参数，并返回一个 BaseMessage 对象作为结果。\n",
    "\n",
    "比如：\n",
    "LLMs.invoke：输入输出都是字符串\n",
    "ChatModels.invoke：输入输出都是BaseMessage对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61883d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.tongyi import Tongyi\n",
    "llm = Tonyyi()\n",
    "\n",
    "print(llm.invoke(\"你好\"))\n",
    "print(llm(\"你好，今天天气怎么样？\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
